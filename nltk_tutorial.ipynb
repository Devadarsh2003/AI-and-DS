{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is NLTK? NLTK is a string processing library. \n",
      "It takes strings as input and returns strings or lists of strings as output. \n",
      "Whereas, spaCy uses object-oriented approach. \n",
      "When we parse a text, spaCy returns document object whose words and sentences are objects themselves.\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\"What is NLTK? NLTK is a string processing library. \n",
    "It takes strings as input and returns strings or lists of strings as output. \n",
    "Whereas, spaCy uses object-oriented approach. \n",
    "When we parse a text, spaCy returns document object whose words and sentences are objects themselves.\"\"\"\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is NLTK?', 'NLTK is a string processing library.', 'It takes strings as input and returns strings or lists of strings as output.', 'Whereas, spaCy uses object-oriented approach.', 'When we parse a text, spaCy returns document object whose words and sentences are objects themselves.']\n",
      "What is NLTK?\n",
      "NLTK is a string processing library.\n",
      "It takes strings as input and returns strings or lists of strings as output.\n",
      "Whereas, spaCy uses object-oriented approach.\n",
      "When we parse a text, spaCy returns document object whose words and sentences are objects themselves.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "doc = sent_tokenize(corpus)\n",
    "print(doc)\n",
    "for sentences in doc:\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(corpus)\n",
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "#used to tokenize into words. It even splits up words with apostrphis \" sam's \" ---> \"sam\",\"'\",\"s\"\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)\n",
    "# This library thinks fullstop as part of the predecessing wor dexceppt for the last full stop ie for EOF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porterstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"Running\", \"Runs\", \"Runner\",\n",
    " \"Happily\", \"Happiness\",\n",
    "\"Studies\", \"Studying\", \"Studied\", \n",
    "\"Boxes\", \"Boxing\", \n",
    "\"Cried\", \"Crying\", \n",
    "\"Plays\", \"Played\", \"Stronger\", \n",
    "\"Quickly\", \n",
    "\"Nationalization\", \"Organization\", \"Denationalized\", \n",
    "\"Cats\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ------> run\n",
      "Runs ------> run\n",
      "Runner ------> runner\n",
      "Happily ------> happili\n",
      "Happiness ------> happi\n",
      "Studies ------> studi\n",
      "Studying ------> studi\n",
      "Studied ------> studi\n",
      "Boxes ------> box\n",
      "Boxing ------> box\n",
      "Cried ------> cri\n",
      "Crying ------> cri\n",
      "Plays ------> play\n",
      "Played ------> play\n",
      "Stronger ------> stronger\n",
      "Quickly ------> quickli\n",
      "Nationalization ------> nation\n",
      "Organization ------> organ\n",
      "Denationalized ------> denation\n",
      "Cats ------> cat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "for word in words:\n",
    "    print(word,\"------>\",stemming.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regexp Stemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running -----> Runn\n",
      "Runs -----> Run\n",
      "Runner -----> Runner\n",
      "Happily -----> Happily\n",
      "Happiness -----> Happines\n",
      "Studies -----> Studie\n",
      "Studying -----> Study\n",
      "Studied -----> Studied\n",
      "Boxes -----> Boxe\n",
      "Boxing -----> Box\n",
      "Cried -----> Cried\n",
      "Crying -----> Cry\n",
      "Plays -----> Play\n",
      "Played -----> Played\n",
      "Stronger -----> Stronger\n",
      "Quickly -----> Quickly\n",
      "Nationalization -----> Nationalization\n",
      "Organization -----> Organization\n",
      "Denationalized -----> Denationalized\n",
      "Cats -----> Cat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "regexp = RegexpStemmer(\"ing$|s$|e$|able$\", min=4)\n",
    "for word in words:\n",
    "    print(word,\"----->\",regexp.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running -----> run\n",
      "Runs -----> run\n",
      "Runner -----> runner\n",
      "Happily -----> happili\n",
      "Happiness -----> happi\n",
      "Studies -----> studi\n",
      "Studying -----> studi\n",
      "Studied -----> studi\n",
      "Boxes -----> box\n",
      "Boxing -----> box\n",
      "Cried -----> cri\n",
      "Crying -----> cri\n",
      "Plays -----> play\n",
      "Played -----> play\n",
      "Stronger -----> stronger\n",
      "Quickly -----> quick\n",
      "Nationalization -----> nation\n",
      "Organization -----> organ\n",
      "Denationalized -----> denation\n",
      "Cats -----> cat\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')\n",
    "for word in words:\n",
    "    print(word,\"----->\",snowball.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "porter vs snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli', 'goe')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"), stemming.stem(\"sportingly\"),stemming.stem(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport', 'goe')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem(\"fairly\"),snowball.stem(\"sportingly\"), snowball.stem(\"goes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
